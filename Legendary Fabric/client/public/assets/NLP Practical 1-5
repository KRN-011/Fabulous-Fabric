{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SMXVf3xwgNhYEsRilormupSAYz5kIoV5","timestamp":1722485748651}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Enrollment No:- 2101031000154\n","\n","Name :- PATEL MANAV"],"metadata":{"id":"vCwQpl3_o8z5"}},{"cell_type":"markdown","source":["PRACTICAL  1\n","\n","AIM:- Explore different NLP libraries."],"metadata":{"id":"LfemDlTsz6B6"}},{"cell_type":"markdown","source":[],"metadata":{"id":"UeX9wcAHssvT"}},{"cell_type":"code","source":["1. NLTK Natural Language Toolkit\n","Description: A library designed for working with human language data (text). It provides easy access to various linguistic resources and tools.\n","Features: Tokenization, stemming, lemmatization, part-of-speech tagging, parsing, and text classification.\n","Installation: pip install nltk\n","Website: nltk.org\n","2. spaCy\n","Description: An advanced library for industrial-strength NLP. It emphasizes performance and ease of use, making it ideal for production environments.\n","Features: Tokenization, named entity recognition, dependency parsing, part-of-speech tagging, and word vectors.\n","Installation: pip install spacy\n","Website: spacy.io\n","3. re (Regular Expressions)\n","Description: The built-in Python module for working with regular expressions, which are useful for text processing tasks such as pattern matching and string manipulation.\n","Features: Searching, splitting, matching, and replacing strings based on regular expressions.\n","Usage: No installation required as itâ€™s included with Python.\n","Documentation: docs.python.org/re\n","4. scikit-learn\n","Description: A library for machine learning that provides simple and efficient tools for data mining and data analysis.\n","Features: Text vectorization (e.g., CountVectorizer, TfidfVectorizer), classification, clustering, regression, and model evaluation.\n","Installation: pip install scikit-learn\n","Website: scikit-learn.org\n","5. NumPy\n","Description: A fundamental package for scientific computing with Python, providing support for arrays and matrices.\n","Features: Array operations, numerical computations, and linear algebra.\n","Installation: pip install numpy\n","Website: numpy.org\n","6. Pandas\n","Description: A powerful data analysis and manipulation library for Python. It provides data structures like DataFrames for handling and analyzing large datasets.\n","Features: Data manipulation, cleaning, and analysis with DataFrames and Series.\n","Installation: pip install pandas\n","Website: pandas.pydata.org\n","7. Matplotlib\n","Description: A plotting library for creating static, animated, and interactive visualizations in Python.\n","Features: Plotting graphs, charts, and other visualizations.\n","Installation: pip install matplotlib\n","Website: matplotlib.org\n","8. Seaborn\n","Description: A statistical data visualization library based on Matplotlib that provides a high-level interface for drawing attractive and informative statistical graphics.\n","Features: Enhanced visualizations with simple syntax, including heatmaps, time series plots, and more.\n","Installation: pip install seaborn\n","Website: seaborn.pydata.org"],"metadata":{"id":"lCUdAyB60UWb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["PRACTICAL -2\n","\n","AIM:- Implement tokenization, stemming, and lemmatization on a sample text."],"metadata":{"id":"iU-P1M7SwCb7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOB3buXTvo1b","outputId":"082fa0df-d527-450e-b94b-dbc1dc2ffc86"},"outputs":[{"output_type":"stream","name":"stdout","text":["['There', 'are', 'multiple', 'ways', 'we', 'can', 'perform', 'tokenization', 'on', 'given', 'text', 'data.', 'We', 'can', 'choose', 'any', 'method', 'based', 'on', 'langauge,', 'library', 'and', 'purpose', 'of', 'modeling.']\n"]}],"source":["text = \"\"\"There are multiple ways we can perform tokenization on given text data. We can choose any method based on langauge, library and purpose of modeling.\"\"\"\n","# Split text by whitespace\n","tokens = text.split()\n","print(tokens)"]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","# Create a Porter Stemmer instance\n","porter_stemmer = PorterStemmer()\n","\n","# Example words for stemming\n","words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n","\n","# Apply stemming to each word\n","stemmed_words = [porter_stemmer.stem(word) for word in words]\n","\n","# Print the results\n","print(\"Original words:\", words)\n","print(\"Stemmed words:\", stemmed_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuAd5GOdyLLS","outputId":"c56a7bc3-e8b4-47fc-dce0-909503b0af62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original words: ['running', 'jumps', 'happily', 'running', 'happily']\n","Stemmed words: ['run', 'jump', 'happili', 'run', 'happili']\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Load the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Define a sample text\n","text = \"The quick brown foxes are jumping over the lazy dogs.\"\n","\n","# Process the text using spaCy\n","doc = nlp(text)\n","\n","# Extract lemmatized tokens\n","lemmatized_tokens = [token.lemma_ for token in doc]\n","\n","# Join the lemmatized tokens into a sentence\n","lemmatized_text = ' '.join(lemmatized_tokens)\n","\n","# Print the original and lemmatized text\n","print(\"Original Text:\", text)\n","print(\"Lemmatized Text:\", lemmatized_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wC6hHzXqy1rq","outputId":"66f6c4e7-74d6-4b89-e31b-616fbf8c0f86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text: The quick brown foxes are jumping over the lazy dogs.\n","Lemmatized Text: the quick brown fox be jump over the lazy dog .\n"]}]},{"cell_type":"markdown","source":["PRACTICAL  3\n","\n","AIM:- Write regular expressions to extract dates, email addresses, and phone numbers from\n","a given text."],"metadata":{"id":"ox-IbWEP0a0i"}},{"cell_type":"code","source":["import re\n","\n","text = \"The event is scheduled for 2024-07-30, but it could also be on 30/07/2024 or 07-30-2024. Alternatively, it might be on 30 July 2024.\"\n","\n","date_pattern = r'\\b(?:\\d{4}[-/]\\d{2}[-/]\\d{2}|\\d{2}[-/]\\d{2}[-/]\\d{4}|\\d{2} \\w+ \\d{4})\\b'\n","dates = re.findall(date_pattern, text)\n","\n","print(\"Dates found:\", dates)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0jt6HYA0c0y","outputId":"0483b125-4fb5-4cb9-8803-704fcd247a1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dates found: ['2024-07-30', '30/07/2024', '07-30-2024', '30 July 2024']\n"]}]},{"cell_type":"code","source":["import re\n","\n","text = \"Please contact us at support@example.com or sales@company.org for more information.\"\n","\n","email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n","emails = re.findall(email_pattern, text)\n","\n","print(\"Email addresses found:\", emails)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSfTZAMm2LSZ","outputId":"a2f08ebe-c249-4ae2-e22f-503d627ba502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Email addresses found: ['support@example.com', 'sales@company.org']\n"]}]},{"cell_type":"code","source":["import re\n","\n","text = \"Call us at (123) 456-7890, 123-456-7890, or 123.456.7890. You can also reach us at +1 123-456-7890 or 1234567890.\"\n","\n","phone_pattern = r'\\b(?:\\+\\d{1,2}\\s?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n","phones = re.findall(phone_pattern, text)\n","\n","print(\"Phone numbers found:\", phones)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbTgVnbn2Qt5","outputId":"93b3f1e2-28b9-4f29-97d4-33f0d8e0157d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Phone numbers found: ['123) 456-7890', '123-456-7890', '123.456.7890', '123-456-7890', '1234567890']\n"]}]},{"cell_type":"markdown","source":["PRACTICAL  4\n","\n","AIM:- Practice pattern matching and text cleaning using Python's re library."],"metadata":{"id":"mO52SE0y4lzq"}},{"cell_type":"code","source":["import re\n","\n","text = \"The event is scheduled for 2024-07-30, but it could also be on 30/07/2024 or 07-30-2024. Alternatively, it might be on 30 July 2024.\"\n","\n","date_pattern = r'\\b(?:\\d{4}[-/]\\d{2}[-/]\\d{2}|\\d{2}[-/]\\d{2}[-/]\\d{4}|\\d{2} \\w+ \\d{4})\\b'\n","dates = re.findall(date_pattern, text)\n","\n","print(\"Dates found:\", dates)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTHGFMbv4oVI","outputId":"bdf33a64-39d1-4cac-da62-ef9e655af175"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dates found: ['2024-07-30', '30/07/2024', '07-30-2024', '30 July 2024']\n"]}]},{"cell_type":"code","source":["import re\n","\n","text = \"Please contact us at support@example.com or sales@company.org for more information.\"\n","\n","email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n","emails = re.findall(email_pattern, text)\n","\n","print(\"Email addresses found:\", emails)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eCHvPRz4r8Q","outputId":"731a708c-ce7c-43dc-fa0c-9a9ca9459fc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Email addresses found: ['support@example.com', 'sales@company.org']\n"]}]},{"cell_type":"code","source":["import re\n","\n","text = \"Call us at (123) 456-7890, 123-456-7890, or 123.456.7890. You can also reach us at +1 123-456-7890 or 1234567890.\"\n","\n","phone_pattern = r'\\b(?:\\+\\d{1,2}\\s?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n","phones = re.findall(phone_pattern, text)\n","\n","print(\"Phone numbers found:\", phones)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOU0WVrq4vVS","outputId":"0d624d5d-2b36-4ce8-ccc1-50359960c029"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Phone numbers found: ['123) 456-7890', '123-456-7890', '123.456.7890', '123-456-7890', '1234567890']\n"]}]},{"cell_type":"markdown","source":["PRACTICAL  5\n","\n","AIM:- Perform POS tagging on a given corpus using NLTK and spaCy."],"metadata":{"id":"J1nVn6VqIFdK"}},{"cell_type":"markdown","source":["Q 1 .What is tokenization ?\n","\n","Tokenization is the process of breaking down a text into smaller units called tokens. These tokens can be words, phrases, or even individual characters, depending on the task at hand.\n","\n","In the code you provided, the word_tokenize function from the NLTK library is used to tokenize the sentence \"My name is manav and i am from ahmedabad\" into a list of words.\n","\n","Q 2 What is POS tagging\n","\n","POS tagging, or Part-of-Speech tagging, is the process of assigning grammatical tags (like noun, verb, adjective, etc.) to each token in a text.\n","\n","In your provided code, the nltk.pos_tag function is used to perform POS tagging on the tokens generated earlier. This results in a list of tuples, where each tuple contains a token and its corresponding POS tag.\n","\n","For example, the POS tag for the token \"manav\" is \"NNP\" which stands for \"Proper Noun, Singular\".\n","\n","POS tagging is helpful in various NLP applications, such as:\n","\n","Sentiment analysis: Identifying adjectives and adverbs can help determine the sentiment expressed in a text.\n","\n","Q 3 Why we use POS tagging?\n","\n","POS tagging is a fundamental step in many Natural Language Processing (NLP) tasks. Here's why it's used:\n","\n","1. Understanding Sentence Structure:\n","\n","POS tags provide information about the grammatical role of each word in a sentence. This helps in understanding the relationships between words and how they contribute to the overall meaning.\n","2. Feature Engineering for Machine Learning:\n","\n","POS tags can be used as features in machine learning models for NLP tasks. For example, in sentiment analysis, knowing whether a word is an adjective or adverb can be crucial for determining the sentiment expressed.\n","3. Specific NLP Applications:\n","\n","Named Entity Recognition (NER): Identifying nouns and their types helps in extracting entities like people, organizations, and locations.\n","Word Sense Disambiguation (WSD): POS tags help in determining the correct meaning of a word based on its context.\n","Machine Translation: Knowing the grammatical function of words aids in generating accurate translations.\n","Text Summarization: POS tags help in identifying important words and phrases to include in a summary.\n","4. Improved Text Analysis:\n","\n","POS tagging enables more sophisticated analysis of text, going beyond simple word counts. It allows you to consider the grammatical roles and relationships between words."],"metadata":{"id":"iJqV_b-9DAFb"}},{"cell_type":"code","source":[],"metadata":{"id":"IcbUd5xLIs3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importing the NLTK library\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","sent = \"My name is manav and i am from ahmedabad\"\n","tokens = word_tokenize(sent)\n","print(tokens)\n","pos_tags = nltk.pos_tag(tokens)\n","print(pos_tags)\n","\n"],"metadata":{"id":"bZUi7cSU9DVN","executionInfo":{"status":"ok","timestamp":1722483982845,"user_tz":-330,"elapsed":454,"user":{"displayName":"","userId":""}},"outputId":"9c256b30-c88b-468c-d4a1-2ca057d317a2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["['My', 'name', 'is', 'manav', 'and', 'i', 'am', 'from', 'ahmedabad']\n","[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('manav', 'JJ'), ('and', 'CC'), ('i', 'JJ'), ('am', 'VBP'), ('from', 'IN'), ('ahmedabad', 'NN')]\n"]}]},{"cell_type":"code","source":["import spacy\n","nlp=spacy.load(\"en_core_web_sm\")\n","sentence=\"My name is manav and i am from ahmedabad\"\n","doc=nlp(sentence)\n","for token in doc:\n","    print(token.text,token.pos_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPrOuIs4rmbe","executionInfo":{"status":"ok","timestamp":1722511531909,"user_tz":-330,"elapsed":16585,"user":{"displayName":"MANAV PATEL","userId":"15882080515919650377"}},"outputId":"459a3287-c727-48e0-ed18-5e4c19c52151"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["My PRON\n","name NOUN\n","is AUX\n","manav NOUN\n","and CCONJ\n","i PRON\n","am AUX\n","from ADP\n","ahmedabad NOUN\n"]}]}]}